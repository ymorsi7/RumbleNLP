<!DOCTYPE HTML>

<html>

<head>
	<title>About</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
	<link rel="stylesheet" href="assets/css/snippet.css">
	<link rel="icon" type="image/x-icon" href="images/pic01.jpeg">
</head>

<body class="is-preload">
	<div id="page-wrapper">

		<!-- Header -->
		<header id="header">
			<h1 id="logo"><a href="index.html">HateSpeechNLP</a></h1>
			<nav id="nav">
				<ul>
					<li><a href="index.html">Home</a></li>
					<li>
						<a href="#">About</a>
						<ul>
							<li><a href="#tf">TF-IDF Vectorization</a></li>
							<li><a href="#dt">Decision Tree</a></li>
							<li><a href="#sa">Sentiment Analysis</a></li>
							<li><a href="#wc">Word Clouds</a></li>
						</ul>
					</li>
					<li><a href="https://github.com/ymorsi7/HateSpeechNLP" target="blank"><i
								class="fa-brands fa-github"></i></a></li>
				</ul>

				</li>
				</ul>
			</nav>
		</header>



		<!-- Main -->
		<div id="main" class="wrapper style1">
			<div class="container" id="tf">
				<header class="major">
					<h2>About</h2>
					<p>Below are descriptions of the tasks done to complete this project</p>
				</header>


				<div id="main">
					<p>Before working with the data that I scraped, I needed to clean it. Thankfully, because I manually
						attained my data, it was already in a clean format, and all that I needed to do was drop the
						unnecessary columns.</p>
				</div>


				<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
				<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
				</script>

				<div class="row gtr-150">
					<div class="col-4 col-12-medium">
						<!-- Sidebar -->
						<section id="sidebar">
							<section>
								<h3>TF-IDF Vectorization</h3>

								<p>
									\[TF = {num\ of\ instances\ of\ word\ in\ doc \over total\ number\ of\ words\ in\
									doc}\]
								</p>

								<p>
									\[IDF = \log({num\ of\ docs\ in\ corpus \over num\ of\ docs\ with\ term})\]
								</p>

								<p>The TF-IDF is calculated by multiplying the TF (term frequency) and IDF (inverse
									document frequency).</p>
								<p>Below is the function I used to find the top n words in a corpus. In our case, the
									corpus was the comments section of the selected videos.

									First, we create a TF-IDF vectorizer object. Then, we fit the vectorizer to the
									corpus. After that, we create a dataframe of the top n words in the corpus, and
									return it to the user.</p>


								<p>Click <a
										href="https://github.com/ymorsi7/HateSpeechNLP#term-frequency-inverse-document-frequency-tf-idf"
										target="blank">here</a> to see the function for this.</p>


								<p>Below is a list of the top 15 words from the comments found with TF-IDF
									vectorization:</p>
								<code>
													&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tfidf<br>
													be&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.245173<br>
													injured&nbsp;&nbsp;&nbsp;0.243024<br>
													affected&nbsp;&nbsp;0.243024<br>
													more&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.234565<br>
													would&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.223824<br>
													woman&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.211882<br>
													in&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.198536<br>
													their&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.189318<br>
													even&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.185259<br>
													those&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.185259<br>
													being&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.175961<br>
													than&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.161941<br>
													by&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.151469<br>
													combat&nbsp;&nbsp;&nbsp;&nbsp;0.149216<br>
													it&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0.145994<br>


												</code>
								<br>

								<p>Click <a href="https://github.com/ymorsi7/HateSpeechNLP#video-1"
										target="blank">here</a> to see the top 15 words for the individual videos.</p>



								<p>The TF-IDF localization proved to be useful, as it shows the prevelance of words such
									as "woman," "injured," and "affected" in the comments. This is useful, as it shows
									that the users are engaged in their respective videos, and have a lot to say about
									women.

								</p>



								<h3 id="sa">Sentiment Analysis</h3>

								<p>Using <a href="https://www.meaningcloud.com/" target="blank">MeaningCloud</a>, I was
									able to conduct sentiment analysis on the comments, which can be found <a
										href="https://github.com/ymorsi7/HateSpeechNLP/tree/main/csv/sentimentAnalysis.csv">here</a>.
								</p>

								<p>The main two numbers I observed were the irony and the agreement/disagreement
									proportions, but I spent more attention on the former. I was able to find that over
									<b>97%</b> of the comments were unironic, and that <b>35%</b> of the comments showed
									disagreement.</p>

								<p>The percentage of unironic comments shows that the users are serious about their
									beliefs, and not just joking around, which is a rather common justification for hate
									speech.</p>


							</section>
						</section>

					</div>

					<div class="col-8 col-12-medium imp-medium" id="dt">

						<!-- Content -->
						<section id="content">
							<a href="#" class="image fit"><img src="images/pic05.jpeg" alt="" /></a>
							<h3>Decision Tree Model</h3>
							<p>To train the hate speech detection model, I used Kaggle's <a
									href="https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset"
									target="blank">"Hate Speech and Offensive Language Dataset."</a></p>
							<p>After importing NLTK, I loaded in the labeled Kaggle data, preprocessed it, and split it,
								as done in <a href="https://copyassignment.com/hate-speech-detection/">this
									tutorial.</a></p>
							<p>After using scikit-learn's DecisionTreeClassifier() function, I trained the model on the
								data, and then tested it on the test data. The model achieved an accuracy of about 0.89,
								which is pretty good.</p>

							<body>

								<pre><code class="python">
binClfr = [] # list (0 or 1)
numHate = 0 # a counter for the number of hate comments
for i in range(len(commentsList)):
	inp = cv.transform([commentsList[i]]).toarray()
	if (model.predict(inp) == ['Offensive Speech']):
		binClfr.append(1) # add one if offensive
		numHate += 1
	elif (model.predict(inp) == ['No Hate and Offensive Speech']):
		binClfr.append(0) # add zero if comment is not hate speech
	else:
		binClfr.append(9) # Add 9 if output it neither (shouldn't happen; means that there's an error)
	print(model.predict(inp))
</code></pre>
							</body>

							<pre><code class="python">
print("Percentage of hate speech comments: " + str(numHate/len(binClfr)))
								</code></pre>

							<p>The above code, meant to find the percentage of hate speech comments, yielded <b>.26</b>,
								which shows that over one quarter of the comments on these videos are hate speech.</p>

							<p> The NLP analysis conducted shows us that a significant percentage of comments on the
								videos relating to sexism on Rumble contain hate speech. Case studies above show that
								there are various types of sexism on the platform, but all in all, they come together to
								form a staggering 26% of the comments found on the videos.

							</p>


							<h3 id="wc">Word Clouds (Bonus)</h3>
							<p>Using the Google Sheets extensions <a href="https://www.meaningcloud.com/"
									target="blank">MeaningCloud</a> and <a href="https://www.chartexpo.com"
									target="blank">ChartExpo</a>, I was able to create word clouds from extracted
								topics, deep categorization, text clustering, and IPTC text classification.</p>

							<p>The CSV files containing the extracted topics, deep categorization, text clustering, and
								IPTC text classification can be found <a
									href="https://github.com/ymorsi7/HateSpeechNLP/tree/main/csv">here</a>.</p>


							<ul>
								<li>Deep Categorization<br><img
										src="https://raw.githubusercontent.com/ymorsi7/HateSpeechNLP/main/wordclouds/deepCategorization.png"
										width=80%></li>
								<li>Text Clustering<br><img
										src="https://raw.githubusercontent.com/ymorsi7/HateSpeechNLP/main/wordclouds/textClustering.png"
										width=80%></li>
								<li>IPTC Text Classification<br><img
										src="https://raw.githubusercontent.com/ymorsi7/HateSpeechNLP/main/wordclouds/iptc.png"
										width=80%></li>
								<li>Topics Extraction<br><img
										src="https://raw.githubusercontent.com/ymorsi7/HateSpeechNLP/main/wordclouds/topicExt.png"
										width=80%></li>
							</ul>
						</section>

					</div>
				</div>
			</div>
		</div>

		<!-- Footer -->
		<footer id="footer">
			<ul class="icons">
				<li><a href="https://github.com/ymorsi7/HateSpeechNLP" class="icon brands alt fa-github"><span
							class="label">GitHub</span></a></li>
			</ul>
			<ul class="copyright">
				<li>&copy; 2022. All rights reserved.</li>
			</ul>
		</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/jquery.dropotron.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>
	<script src="https://kit.fontawesome.com/97ac8d9bb6.js" crossorigin="anonymous"></script>
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>


</body>

</html>